# CADGen: Advanced 3D CAD Model Generation Framework

CADGen is a state-of-the-art deep learning framework for generating 3D CAD models from multi-view images. The project enables the conversion of 2D representations (front, top, and side views) into precise 3D CAD models with accurate command sequences and parameters.

<p align="center">
  <img src="docs/assets/cadgen-overview.png" alt="CADGen Overview" width="800"/>
  <br>
  <em>CADGen: Generating 3D CAD models from 2D multi-view inputs</em>
</p>

## ğŸ” Features

- **Multi-view to 3D Conversion**: Transform 2D images into complete 3D CAD models
- **Multiple Model Architectures**:
  - ğŸ”¹ Autoregressive models for sequential generation
  - ğŸ”¹ Set Transformer-based models for global reasoning
  - ğŸ”¹ Deformable models for complex geometry understanding
- **Point Cloud Processing**: Advanced point cloud generation and manipulation
- **Comprehensive Evaluation**: Robust metrics for assessing generation quality

## ğŸ—ï¸ Project Structure

The CADGen project is organized into several interconnected modules, each with a specific role in the 3D CAD generation pipeline:

### Core Modules

```
CADGen/
â”œâ”€â”€ 3dmodel/                     # Core model implementation
â”‚   â”œâ”€â”€ model/                   # Model architecture definitions
â”‚   â”‚   â”œâ”€â”€ model.py             # Base model definitions
â”‚   â”‚   â”œâ”€â”€ model_simple.py      # Simplified model variant
â”‚   â”‚   â”œâ”€â”€ transformer.py       # Transformer components
â”‚   â”‚   â””â”€â”€ loss.py              # Loss functions
â”‚   â”œâ”€â”€ datasets/                # Dataset handling for training
â”‚   â”‚   â”œâ”€â”€ dataset.py           # Core dataset classes
â”‚   â”‚   â””â”€â”€ augmentation.py      # Data augmentation strategies
â”‚   â”œâ”€â”€ cadlib/                  # CAD processing and manipulation
â”‚   â”‚   â”œâ”€â”€ cad_utils.py         # CAD operation utilities
â”‚   â”‚   â””â”€â”€ command_parser.py    # CAD command parsing
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration handling
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging utilities
â”‚   â”‚   â””â”€â”€ vis_utils.py         # Visualization helpers
â”‚   â”œâ”€â”€ train.py                 # Base model training script
â”‚   â”œâ”€â”€ train_deformable.py      # Deformable model training
â”‚   â”œâ”€â”€ train_deformable_cad.py  # Deformable CAD model training
â”‚   â””â”€â”€ test.py                  # Model testing and evaluation
```

### Model Variants

The project includes specialized model architectures, each designed to address specific aspects of the CAD generation task:

```
CADGen/
â”œâ”€â”€ 3dmodel_autoregressive/      # Sequential CAD generation models
â”‚   â”œâ”€â”€ model/                   # Autoregressive architecture
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â””â”€â”€ inference.py             # Inference utilities
â”‚
â”œâ”€â”€ 3dmodel_autoregressive_pointcloud/ # Point cloud-based autoregressive models
â”‚   â”œâ”€â”€ model/                   # Point cloud sequential model
â”‚   â””â”€â”€ train.py                 # Training script
â”‚
â”œâ”€â”€ 3dmodel_settransformer/      # Set Transformer implementation
â”‚   â”œâ”€â”€ model/                   # Set-based architecture
â”‚   â””â”€â”€ train.py                 # Training script
```

### Data Processing Pipeline

Tools for preparing, converting, and processing CAD data:

```
CADGen/
â”œâ”€â”€ data_process/                # Data preprocessing and conversion
â”‚   â”œâ”€â”€ json2pc_my.py            # Converts JSON CAD to point clouds
â”‚   â”œâ”€â”€ json2vec_my.py           # Converts JSON CAD to vector representations
â”‚   â”œâ”€â”€ data_split.py            # Splits datasets for training/validation
â”‚   â”œâ”€â”€ ply2txt.py               # PLY to text format conversion
â”‚   â””â”€â”€ txt2np.py                # Text to NumPy format conversion
```

### Evaluation Framework

Comprehensive evaluation tools for assessing model performance:

```
CADGen/
â”œâ”€â”€ evaluation/                  # Model evaluation tools
â”‚   â”œâ”€â”€ evaluate_ae_cd.py        # Chamfer distance evaluation
â”‚   â”œâ”€â”€ evaluate_ae_acc.py       # Command accuracy evaluation
â”‚   â”œâ”€â”€ evaluate_gen_torch.py    # Generation quality evaluation
â”‚   â””â”€â”€ utils/                   # Evaluation utilities
â”‚       â”œâ”€â”€ metrics.py           # Metrics implementation
â”‚       â””â”€â”€ visualization.py     # Results visualization
```

### Advanced Approaches

Specialized modules for advanced techniques:

```
CADGen/
â””â”€â”€ bulletpoints/                # Specialized modeling approaches
    â””â”€â”€ mae_cad/                 # Masked Autoencoder for CAD modeling
        â”œâ”€â”€ models_command.py    # Command prediction models
        â”œâ”€â”€ models_parameter_*.py # Parameter prediction variants
        â”œâ”€â”€ main_*.py            # Training scripts
        â””â”€â”€ README.md            # Module-specific documentation
```

### Data Flow

The overall data flow in the CADGen framework follows this pattern:

1. **Data Preparation**: Raw CAD models â†’ Processed command sequences and point clouds
2. **Model Training**: Multi-view images + CAD data â†’ Trained models
3. **Inference**: New multi-view images â†’ Generated 3D CAD models
4. **Evaluation**: Generated models vs. Ground truth â†’ Performance metrics

## âš™ï¸ Requirements

- PyTorch 1.9+
- CUDA-enabled GPU (8GB+ recommended)
- NumPy
- timm (PyTorch Image Models)
- Tensorboard

## ğŸš€ Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/your-username/CADGen.git
   cd CADGen
   ```

2. **Install dependencies**:
   ```bash
   # Create a virtual environment (recommended)
   python -m venv cadgen-env
   source cadgen-env/bin/activate  # On Windows: cadgen-env\Scripts\activate
   
   # Install required packages
   pip install torch==1.9.0 torchvision==0.10.0 numpy==1.20.3 tensorboard==2.6.0 timm==0.4.12
   ```

## ğŸ“Š Usage

### Data Preparation

Prepare your data using the processing scripts:

```bash
# Split your dataset
python data_process/data_split.py --input /path/to/data --output /path/to/output

# Convert JSON CAD data to point clouds
python data_process/json2pc_my.py --input /path/to/json --output /path/to/pointclouds
```

### Training

Train different model variants:

```bash
# Basic model training
python 3dmodel/train.py --config configs/base_config.yaml

# Deformable model training
python 3dmodel/train_deformable.py --config configs/deformable_config.yaml

# Deformable CAD model training
python 3dmodel/train_deformable_cad.py --config configs/deformable_cad_config.yaml
```

### Evaluation

Evaluate your trained models:

```bash
# Generation quality evaluation
python evaluation/evaluate_gen_torch.py --model_path /path/to/model --test_data /path/to/test_data

# Chamfer distance evaluation
python evaluation/evaluate_ae_cd.py --model_path /path/to/model --test_data /path/to/test_data
```

## ğŸ§  Model Architectures

The CADGen framework implements several powerful architectures:

### Base Model (Views2Points)

The base model takes multi-view images and generates point clouds representing the 3D shape:

- **Backbone**: ResNet-based feature extraction from each view
- **Fusion Module**: Multi-view feature integration
- **Decoder**: Transformer architecture that outputs 3D points and CAD command sequences

<p align="center">
  <img src="docs/assets/base-model.png" alt="Base Model Architecture" width="600"/>
  <br>
  <em>Views2Points model architecture</em>
</p>

### Deformable Models

The deformable variants incorporate deformable attention mechanisms for better geometric understanding:

- **Deformable Attention**: 3D-aware attention mechanisms that enhance spatial reasoning
- **Point Sampling Strategy**: Adaptive point sampling to focus computation on relevant regions
- **Hierarchical Processing**: Multi-scale feature processing for capturing both global and local details

### Autoregressive Approach

The autoregressive model generates CAD commands sequentially:

- **Command Sequence Modeling**: LSTM/Transformer-based sequence generation
- **Parameter Prediction**: Specialized networks for predicting geometric parameters
- **Joint Learning**: Combined learning of commands and their parameters

## ğŸ“‹ Dataset Format

### Input Images

- Front, top, and side view images (RGB or grayscale)
- Resolution: Recommend 256Ã—256 pixels
- Format: PNG or JPG

### 3D CAD Data

- Point cloud representations (1024 points recommended)
- CAD command sequences in JSON format:
  ```json
  {
    "commands": ["line", "circle", "extrude", ...],
    "parameters": [[x1, y1, z1, x2, y2, z2], [cx, cy, r], [h], ...]
  }
  ```

### Data Organization

```
data/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ front/
â”‚   â”œâ”€â”€ top/
â”‚   â””â”€â”€ side/
â”œâ”€â”€ point_clouds/
â””â”€â”€ cad_commands/
```

## ğŸ“ˆ Performance Metrics

The framework evaluates performance using:

1. **Chamfer Distance (CD)**: Measures the similarity between generated and ground truth point clouds
2. **Command Accuracy**: Percentage of correctly predicted CAD commands
3. **Parameter Error**: Mean squared error between predicted and ground truth parameters
4. **Visual Quality**: Qualitative assessment of the generated 3D models

### Benchmark Results

| Model | CD â†“ | Cmd Acc â†‘ | Param MSE â†“ |
|-------|------|-----------|-------------|
| Base  | -    | -         | -           |
| Deformable | - | -       | -           |
| Autoregressive | - | -   | -           |

## ğŸ–¥ï¸ Inference Examples

Generate a CAD model from input views:

```python
import torch
from model.model_simple import Views2Points

# Load model
model = Views2Points(args)
model.load_state_dict(torch.load('path/to/model_checkpoint'))
model.eval()

# Load input images
front_img = load_image('front.png')
top_img = load_image('top.png')
side_img = load_image('side.png')

# Generate CAD model
with torch.no_grad():
    output = model(front_img, top_img, side_img)
    
# Extract commands and parameters
commands = output['pred_commands']
parameters = output['pred_args']

# Save or visualize the result
save_cad_model(commands, parameters, 'output.obj')
```

## ğŸ”§ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   - Reduce batch size in the config
   - Use model variants with fewer parameters
   - Enable gradient checkpointing

2. **Slow Training**
   - Use mixed precision training (enabled by default)
   - Optimize data loading with more workers
   - Check for bottlenecks using profiling tools

3. **Poor Generation Quality**
   - Ensure training data quality and diversity
   - Try different model variants
   - Adjust loss function weights in `CADLoss` class

### Environment Setup Issues

For environment setup problems, make sure you have:
- CUDA toolkit compatible with your PyTorch version
- Sufficient GPU memory (8GB+ recommended)
- All dependencies installed with compatible versions

## ğŸ¤ Contributing

Contributions to CADGen are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please ensure your code follows the project's style guidelines and includes appropriate tests.

## ğŸ”® Future Work

- Integration with popular CAD software
- Support for more complex CAD operations
- Web-based interface for model generation
- Mobile deployment options
- Cross-domain adaptations (architectural, mechanical, etc.)

## ğŸ“„ License

[Add your license information here]

## ğŸ™ Acknowledgements

[Add acknowledgements, citations, or references to papers that inspired this work]

## ğŸ“¬ Contact

[Add contact information]
